<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Publications on Emilie Yu</title><link>https://em-yu.github.io/research/</link><description>Recent content in Publications on Emilie Yu</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 01 Feb 2021 14:26:10 +0100</lastBuildDate><atom:link href="https://em-yu.github.io/research/index.xml" rel="self" type="application/rss+xml"/><item><title>WORM: Programming Collaborative Robots Through Manual Actions for Craft-Aligned Digital Fabrication</title><link>https://em-yu.github.io/research/worm/</link><pubDate>Sun, 24 Aug 2025 12:26:00 +0100</pubDate><guid>https://em-yu.github.io/research/worm/</guid><description>We seek to enable artists to precisely specify domain-specific machining operations to be executed by a cobot (collaborative robot arm). We contribute a novel cobot programming framework that allows artists to use manual interaction with the robot to define robotic behaviors.</description></item><item><title>Computational Craft: Computational Fabrication Methods for Craft Production</title><link>https://em-yu.github.io/research/siggraph_2025_course/</link><pubDate>Sun, 24 Aug 2025 11:26:00 +0100</pubDate><guid>https://em-yu.github.io/research/siggraph_2025_course/</guid><description>This course introduce Siggraph attendees to foundational concepts and methods in applying computational design and digital fabrication techniques to craft production. We covered methods from ceramics and textiles production, highlighting our own research and other work in these fields, and pointing out future opportunities for graphics researchers to do work on computational craft.</description></item><item><title>Towards a sustainable use of GPUs in Graphics Research</title><link>https://em-yu.github.io/research/siggraph_towards_sustainable_gpus/</link><pubDate>Thu, 29 May 2025 11:26:00 +0100</pubDate><guid>https://em-yu.github.io/research/siggraph_towards_sustainable_gpus/</guid><description>We surveyed 888 SIGGRAPH papers from 2018-2024 and gathered author-reported GPU models. By contextualizing the hardware reported in papers with available data of consumers&amp;rsquo; hardware, we demonstrate that research is consistently developed and tested on new high-end devices that do not reflect the state of the consumer-level market.</description></item><item><title>texTile: Making and Re-making Crochet Granny Square Garments Through Computational Design and 3D-printed Connectors</title><link>https://em-yu.github.io/research/textile/</link><pubDate>Sun, 27 Apr 2025 11:26:00 +0100</pubDate><guid>https://em-yu.github.io/research/textile/</guid><description>texTile is a modular fashion workflow that enables designers to assemble reusable crochet tiles into garments. To support this workflow, we developed digitally fabricated connectors for easy assembly and disassembly, a custom pattern solver and user interface to guide garment design, and a visualization tool to help plan manual assembly and reassembly.</description></item><item><title>3D-Layers: Bringing Layer-Based Color Editing to VR Painting</title><link>https://em-yu.github.io/research/3dlayers/</link><pubDate>Sun, 05 May 2024 11:26:00 +0100</pubDate><guid>https://em-yu.github.io/research/3dlayers/</guid><description>VR artists create beautiful 3D paintings with colored 3D brushstrokes. We investigate how the paradigm of ``painting layers&amp;rsquo;&amp;rsquo; could translate to the 3D painting space to achieve non-destructive color editing effects.</description></item><item><title>PhD Thesis: Designing Tools for 3D Content Authoring Based on 3D Sketching</title><link>https://em-yu.github.io/research/phd-tesis/</link><pubDate>Sun, 03 Mar 2024 18:56:27 +0100</pubDate><guid>https://em-yu.github.io/research/phd-tesis/</guid><description>3D strokes: what are they? what can we use them for?</description></item><item><title>VideoDoodles: Hand-Drawn Animations on Videos with Scene-Aware Canvases</title><link>https://em-yu.github.io/research/videodoodles/</link><pubDate>Tue, 09 May 2023 14:26:10 +0100</pubDate><guid>https://em-yu.github.io/research/videodoodles/</guid><description>We study how artists create VideoDoodles (mix of video and hand-drawn animation) and propose a novel user interface to simplify this task based on depth and motion priors.</description></item><item><title>Piecewise-Smooth Surface Fitting onto Unstructured 3D Sketches</title><link>https://em-yu.github.io/research/surfacing_3d_sketches/</link><pubDate>Wed, 01 Jun 2022 14:26:10 +0100</pubDate><guid>https://em-yu.github.io/research/surfacing_3d_sketches/</guid><description>We propose a method to transform unstructured 3D sketches into piecewise smooth surfaces that preserve sketched geometric features.</description></item><item><title>CASSIE: Curve And Surface Sketching in Immersive Environments</title><link>https://em-yu.github.io/research/cassie/</link><pubDate>Mon, 01 Feb 2021 14:26:10 +0100</pubDate><guid>https://em-yu.github.io/research/cassie/</guid><description>We prototype a 3D sketching interface in VR, where the user&amp;rsquo;s strokes are automatically neatened to form a well-connected curve network. We additionnaly infer and create surface patches on the sketch, making it possible to create a 3D surface from a few 3D brush strokes.</description></item><item><title>MSc Thesis: Interactive 3D Sketching in Virtual Reality</title><link>https://em-yu.github.io/research/msc-thesis/</link><pubDate>Mon, 03 Aug 2020 18:56:27 +0100</pubDate><guid>https://em-yu.github.io/research/msc-thesis/</guid><description>During my MSc thesis at DTU supervised by &lt;a href="http://people.compute.dtu.dk/janba/">Andreas BÃ¦rentzen&lt;/a>, &lt;a href="http://www-sop.inria.fr/members/Adrien.Bousseau/">Adrien Bousseau&lt;/a> and &lt;a href="https://tiborstanko.sk/">Tibor Stanko&lt;/a>, I implemented a VR sketching application in Unity and experimented with automatic neatening of strokes, formation of curve networks from the strokes, and infering surface patches. We finally conducted a small remote user study. This work was the basis for our next paper, CASSIE.</description></item></channel></rss>